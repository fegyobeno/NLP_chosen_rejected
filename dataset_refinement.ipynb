{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "369452bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the two datasets into one\n",
    "final_data = {}\n",
    "with open('Dataset/magyar_tortenelem_cr.json', 'r', encoding = 'utf-8') as f1, open('Dataset/tortenelem_cr.json', 'r', encoding = 'utf-8') as f2:\n",
    "    data1 = json.load(f1)\n",
    "    data2 = json.load(f2)\n",
    "    id_counter = 0\n",
    "    for key in data1:\n",
    "        final_data[str(id_counter)] = data1[key]\n",
    "        id_counter += 1\n",
    "    \n",
    "    for key in data2:\n",
    "        final_data[str(id_counter)] = data2[key]\n",
    "        id_counter += 1\n",
    "        \n",
    "# save the merged dataset\n",
    "with open('Dataset/data.json', 'w', encoding = 'utf-8') as f_out:\n",
    "    json.dump(final_data, f_out, ensure_ascii = False, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb998ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the quality of the merged dataset with a metric and a LLM call\n",
    "# The metric will be correctness_relevance(chosen) + delta(correctness_relevance(chosen), correctness_relevance(rejected))\n",
    "# The score will be between [0,5] \n",
    "# Entry is accepted if the score is above 5.0\n",
    "client = OpenAI(\n",
    "    base_url=\"http://mobydick.elte-dh.hu:23432/v1\",\n",
    "    api_key=\"7TL4I2Me17MZ2J0zFSAKMMIIpoRXv26A\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03bdaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First example\n",
    "example_1_json = {\n",
    "    \"prompt\": [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "                \"content\": f\"Forrás szöveg: Mussolini apja elkötelezett és szűkebb környezetében elismert szocialista volt. Gyakran megfordultak nála olasz anarchista marxisták, otthonában pedig több ilyen szellemiségű művet tartott - nem csoda, hogy Benito már 17 évesen anarchistának tartotta magát Kérdés: Milyen politikai irányultságúnak tartotta magát Benito Mussolini?\"\n",
    "        }\n",
    "    ],\n",
    "    \"chosen\": [{\"role\": \"assistant\", \"content\": \"Anarchista.\"}],\n",
    "    \"rejected\": [{\"role\": \"assistant\", \"content\": \"Kapitalista.\"}],\n",
    "}\n",
    "\n",
    "\n",
    "score_1_json = {\n",
    "    \"context\" : example_1_json,\n",
    "    \"score\": [\n",
    "        {\n",
    "            \"chosen_score\" : 5.0,\n",
    "            \"rejected_score\" : 0.0\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second example\n",
    "example_2_json = {\n",
    "    \"prompt\": [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "                \"content\": f\"Forrás szöveg: Joszif Sztálin 1904-ben megszökött a száműzetésből, majd Tbiliszibe ment az Egyesült Kaukázusi Bizottságot vezetni. „Credo” címmel programtervezetet készített, amiben hangot adott egyet nem értésének a Párttal, és annak egyes eszméivel kapcsolatos kérdésekkel. Kérdés: Milyen névvel tervezett programtervezetet Sztálin, miután megszökött a száműzetésből?\"\n",
    "        }\n",
    "    ],\n",
    "    \"chosen\": [{\"role\": \"assistant\", \"content\": \"A kommunista manifesztó.\"}],\n",
    "    \"rejected\": [{\"role\": \"assistant\", \"content\": \"Credo.\"}],\n",
    "}\n",
    "\n",
    "\n",
    "score_2_json = {\n",
    "    \"context\" : example_2_json,\n",
    "    \"score\": [\n",
    "        {\n",
    "            \"chosen_score\" : 0.0,\n",
    "            \"rejected_score\" : 5.0\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third example: to provide a contextual understanding as well\n",
    "example_3_json = {\n",
    "    \"prompt\": [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "                \"content\": f\"Forrás szöveg: A két szám összege (vagyis összegük) az a végeredmény, ami akkor adódik, ha a két számot összeadjuk. Kérdés: Mennyi 17 és 35 összege?\"\n",
    "        }\n",
    "    ],\n",
    "    \"chosen\": [{\"role\": \"assistant\", \"content\": \"Az 1914-ben kirobbanó háborút később az első világháborúnak nevezték.\"}],\n",
    "    \"rejected\": [{\"role\": \"assistant\", \"content\": \"~50.\"}],\n",
    "}\n",
    "\n",
    "\n",
    "score_3_json = {\n",
    "    \"context\" : example_3_json,\n",
    "    \"score\": [\n",
    "        {\n",
    "            \"chosen_score\" : 0.0,\n",
    "            \"rejected_score\" : 1.0\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "677a870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = f\"\"\"\n",
    "You are a dataset validator. Assign a score to the chosen and rejected andswer based on correctness and relevance to the source.\n",
    "The score is between 0 and 5, where 0 is completely incorrect/irrelevant and 5 is completely correct/relevant.\n",
    "IMPORTANT: You must include the input json inside the 'prompt' field so the model can read it.\n",
    "\n",
    "### Example 1\n",
    "[Input JSON]:\n",
    "{json.dumps(example_1_json, ensure_ascii=False)}\n",
    "\n",
    "[Target JSON]:\n",
    "{json.dumps(score_1_json, ensure_ascii=False)}\n",
    "\n",
    "### Example 2\n",
    "[Input JSON]:\n",
    "{json.dumps(example_2_json, ensure_ascii=False)}\n",
    "[Target JSON]:\n",
    "{json.dumps(score_2_json, ensure_ascii=False)}\n",
    "\n",
    "### Example 3\n",
    "[Input JSON]:\n",
    "{json.dumps(example_3_json, ensure_ascii=False)}\n",
    "[Target JSON]:\n",
    "{json.dumps(score_3_json, ensure_ascii=False)}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f59fdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an expert dataset validator.\n",
    "Task:\n",
    "1. Analyze the provided [Input JSON].\n",
    "2. Score the chosen and rejected answers based on correctness and relevance to the source.\n",
    "3. Construct a valid JSON object with:\n",
    "   - \"context\": The provided [Input JSON].\"\n",
    "   - \"score_chosen\": The score for the chosen answer.\n",
    "   - \"score_rejected\": The score for the rejected answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce1df2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"prompt\": [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "                \"content\": f\"Forrás szöveg: Az ég kék. Kérdés: Milyen színű az ég?\"\n",
    "        }\n",
    "    ],\n",
    "    \"chosen\": [{\"role\": \"assistant\", \"content\": \"Türkiz kék.\"}],\n",
    "    \"rejected\": [{\"role\": \"assistant\", \"content\": \"Fekete ha este van.\"}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b78bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_chosen_rejected(data):\n",
    "    try:\n",
    "\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=\"zai-org/GLM-4.5-Air-FP8\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": f\"{few_shot_prompt}\\n\\n### New Task\\n[Input Text]:\\n\\\"{data}\\\"\\n\\n[Target JSON]:\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            stream=False,\n",
    "            response_format={\"type\": \"json_object\" }\n",
    "        )\n",
    "        answer_json = chat_completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating dataset entry: {e}\")\n",
    "        answer_json = {}\n",
    "    return answer_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fabea668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_chosen_rejected_dataset(input_file, output_file):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f :\n",
    "        data = json.load(f)\n",
    "    \n",
    "    dataset = {}\n",
    "    \n",
    "    # validate 50 entries\n",
    "    sample_keys = random.sample(list(data.keys()), 50)\n",
    "    \n",
    "\n",
    "    for item in sample_keys:\n",
    "        #print(item, data[item])\n",
    "        t = data[item]\n",
    "        ans = score_chosen_rejected(t)\n",
    "        #print(f\"Generated for item {item}: {ans}\")\n",
    "        try:\n",
    "            json_ans = json.loads(ans)\n",
    "            # Check if keys exist\n",
    "            if not all(k in json_ans for k in [\"context\", \"score\"]):\n",
    "                raise ValueError(\"Missing keys\")\n",
    "            else:\n",
    "                print(f\"Successfully parsed generation for item {item}.\")\n",
    "                dataset[item] = json_ans\n",
    "          \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse generation: {e}\")\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dataset, f, ensure_ascii=False, indent=4)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5c1356e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed generation for item 1454.\n",
      "Successfully parsed generation for item 951.\n",
      "Successfully parsed generation for item 1495.\n",
      "Successfully parsed generation for item 1438.\n",
      "Successfully parsed generation for item 357.\n",
      "Successfully parsed generation for item 86.\n",
      "Successfully parsed generation for item 514.\n",
      "Successfully parsed generation for item 124.\n",
      "Successfully parsed generation for item 128.\n",
      "Successfully parsed generation for item 1419.\n",
      "Successfully parsed generation for item 1022.\n",
      "Successfully parsed generation for item 737.\n",
      "Successfully parsed generation for item 1234.\n",
      "Failed to parse generation: Missing keys\n",
      "Successfully parsed generation for item 239.\n",
      "Successfully parsed generation for item 1246.\n",
      "Successfully parsed generation for item 335.\n",
      "Successfully parsed generation for item 552.\n",
      "Successfully parsed generation for item 1177.\n",
      "Successfully parsed generation for item 1378.\n",
      "Successfully parsed generation for item 445.\n",
      "Successfully parsed generation for item 508.\n",
      "Successfully parsed generation for item 476.\n",
      "Failed to parse generation: Missing keys\n",
      "Successfully parsed generation for item 827.\n",
      "Successfully parsed generation for item 936.\n",
      "Successfully parsed generation for item 470.\n",
      "Successfully parsed generation for item 1380.\n",
      "Successfully parsed generation for item 1286.\n",
      "Successfully parsed generation for item 488.\n",
      "Failed to parse generation: Missing keys\n",
      "Successfully parsed generation for item 517.\n",
      "Successfully parsed generation for item 474.\n",
      "Failed to parse generation: Missing keys\n",
      "Successfully parsed generation for item 404.\n",
      "Successfully parsed generation for item 667.\n",
      "Successfully parsed generation for item 480.\n",
      "Successfully parsed generation for item 978.\n",
      "Successfully parsed generation for item 665.\n",
      "Successfully parsed generation for item 788.\n",
      "Successfully parsed generation for item 407.\n",
      "Successfully parsed generation for item 1435.\n",
      "Failed to parse generation: Missing keys\n",
      "Successfully parsed generation for item 712.\n",
      "Failed to parse generation: Missing keys\n",
      "Successfully parsed generation for item 1091.\n",
      "Successfully parsed generation for item 1491.\n",
      "Successfully parsed generation for item 536.\n",
      "Successfully parsed generation for item 1194.\n",
      "Successfully parsed generation for item 1200.\n"
     ]
    }
   ],
   "source": [
    "validate_chosen_rejected_dataset(\"Dataset/merged_cr.json\", \"Dataset/scored_merged_cr.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed738b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average score of the dataset so that we can have an idea about its quality\n",
    "scores = []\n",
    "with open(\"Dataset/scored_merged_cr.json\", \"r\", encoding=\"utf-8\") as f :\n",
    "    scored_data = json.load(f)\n",
    "    for item in scored_data:\n",
    "        #print(scored_data[item][\"score\"][0].keys())\n",
    "        #print(scored_data[item][\"score\"][0][\"chosen_score\"], scored_data[item][\"score\"][0][\"rejected_score\"])\n",
    "        ch_score = scored_data[item][\"score\"][0][\"chosen_score\"]\n",
    "        rej_score = scored_data[item][\"score\"][0][\"rejected_score\"]\n",
    "        delta = ch_score - rej_score\n",
    "        total_score = ch_score + delta\n",
    "#        print(f\"Item {item} - Total score: {total_score}\")\n",
    "        scores.append(total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe468c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of the dataset - Average score: 9.931818181818182\n"
     ]
    }
   ],
   "source": [
    "print(f\"Quality of the dataset - Average score: {sum(scores)/len(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3541aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to jsonl for Hugging-face schenanigans\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('Dataset/data.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da11ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transposed = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9031c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transposed.to_json('Dataset/data.jsonl', orient='records', lines=True, force_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
